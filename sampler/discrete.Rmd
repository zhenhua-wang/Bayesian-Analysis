---
title: "DiscreteModels"
author: "Zhenhua Wang"
date: "12/7/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Beta-Binomial model

Suppose the outcome of each observation is either 1 or 0 according to a unknown parameter $\theta$. This dataset could be modeled as a binomial sampling model.

$$
\begin{aligned}
y_1, ..., y_n | \theta \sim Binomial(n, \theta)
\end{aligned}
$$

To find the conjugate prior for $\theta$, we rewrite distribution of sampling model proportional to $\theta$.

$$
\begin{aligned}
P(y_1, ..., y_n|theta) 
&\propto \theta^{\sum{y_i}} (1-\theta)^{n - \sum{y_i}}
\end{aligned}
$$

Clearly, its conjugate prior belongs to "beta family". (Same as before, we only consider the terms related to $\theta$)

$$
\begin{aligned}
P(\theta) 
&= dbeta(\theta, a, b) \\
&\propto \theta^{a-1}(1-\theta)^{b-1}
\end{aligned}
$$

Then, we could compute its posterior distribution easily.

$$
\begin{aligned}
P(\theta|y_1, ..., y_n) 
&\propto P(y_1, ..., y_n|\theta)P(\theta) \\
&\propto \theta^{\sum{y_i}} (1-\theta)^{n - \sum{y_i}} \times \theta^{a-1}(1-\theta)^{b-1} \\
&\propto \theta^{(a+\sum y_i)-1} (1-\theta)^{(b + n-\sum y_i)} - 1 \\
\theta|y_1, ..., y_n &\sim Beta(a + \sum y_i, b + n - \sum y_i)
\end{aligned}
$$

After compute the posterior distribution for $\theta$, we could easily write out the sampler for $\theta$

```{r}
beta_binomial_sampler = function(S, y, a, b) {
  y.sum = sum(y)
  n = length(y)
  an = a + y.sum
  bn = b + n - y.sum
  return(rbeta(S, an, bn))
}
```

## Gamma-Poisson model

Poisson distribution is a natural choice when modelling counts. The only parameter for Poisson is its mean ($\theta$). As before, we also write down its sampling model proportional to $\theta$. 

$$
\begin{aligned}
y_1, ..., y_n | \theta &\sim Poisson(\theta) \\
P(y_1, ..., y_n | \theta) &\propto \theta^{\sum y_i}e^{-n\theta}
\end{aligned}
$$

Clearly, the conjugate prior for Poisson distribution is Gamma distribution.

$$
\begin{aligned}
\theta &\sim Gamma(a, b) \\
P(\theta) &\propto \theta^{a-1}e^{-b\theta}
\end{aligned}
$$

Then, we could compute its posterior distribution easily.

$$
\begin{aligned}
P(\theta | y_1, ..., y_n) 
&\propto \theta^{\sum y_i}e^{-n\theta} \times \theta^{a-1}e^{-b\theta} \\
&\propto \theta^{(a + \sum y_i)}e^{-(b+n)\theta} \\
\theta | y_1, ..., y_n &\sim Gamma(a+\sum y_i, b + n)
\end{aligned}
$$

After compute the posterior distribution for $\theta$, we could easily write out the sampler for $\theta$

```{r}
Gamma_Poisson_sampler = function(S, y, a, b) {
  y.sum = sum(y)
  n = length(y)
  an = a + y.sum
  bn = b + n
  return(rgamma(S, an, bn))
}
```